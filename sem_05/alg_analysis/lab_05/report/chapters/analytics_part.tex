\chapter{Аналитическая часть}
В данном разделе будут рассмотрены теоретические основы линейной и параллельной конвейерной обработки данных и алгоритмы токенизации, применения правил к токенам и их сортировки.

\section{Конвейерная обработка данных}
Конвейер~---~способ организации вычислений, используемый в современных процессорах с целью повышения их производительности или, в широком смысле, механизм, который позволяет обрабатывать заявки определённого вида поэтапно. На каждой из лент конвейера выполняется одна из стадий обработки поступающих заявок. 

Каждая лента в контексте разработки программы~---~это функция-обработчик, выполняющая над неким набором данных операции и передающая их следующей функции. Под каждую ленту конвейера (функцию-обработчик) может быть выделен отдельный поток, что позволит дополнительно увеличить быстродействие.

\subsection{Линейная конвейеризация}
При линейной конвейеризации одновременно в системе не может находиться более, чем одна заявка: пока одна заявка полностью не пройдёт цикл конвейера, пройденные ей ленты будут простаивать, а другие заявки в очереди на вход в систему будут находиться в состоянии ожидания. При такой реализации время ожидания в очередях между этапами конвейера заявки, уже вошедшей в систему, будет незначительным или отсутствовать вовсе, так как промежуточные очереди не заполняются.

\subsection{Параллельная конвейеризация}
При параллельной конвейеризации одновременно в системе может находиться несколько заявок, если в данный момент времени они проходят обработку на разных этапах конвейера. Таким образом сокращается время ожидания заявок в первичной очереди, однако промежуточные очереди системы будут наполняться заявками, что приведёт к росту времени ожидания заявки в каждой из них.

\section{Алгоритм токенизации}
Токенизация~---~процесс разделения текста на составляющие (их называют «токенами»). Чаще всего текст разделяется на токены по словам или предложениям. В данной работе принято решение разбивать текст на токены по словам. Отдельные числа и диапазоны чисел будут рассматриваться как один токен.

Для проведения токенизации текст каждого документа просматривается с использованием регулярного выражения $([\string^\text{0-9а-яА-ЯЁё-}])$, которое исключает из рассмотрения все последовательности, кроме состоящих из строчных и заглавных букв русского алфавита, цифр и символа «-» для слов, пишущихся через дефис, и числовых диапазонов.

\section{Алгоритм применения правил к токенам}
После токенизации полученный набор токенов просматривается заново, с целью применения установленных правил. В данной работе используются правила объединения нескольких токенов в один, в случае совпадения с заданной конструкцией. Например, комбинация токенов «и», «так», «далее» может быть рассмотрена как один токен «и так далее».

Правила, применяемые к токенам, в свою очередь также составляются по определённой закономерности: любой токен, указанный в правиле, как целевой при замене, должен находиться ещё в одном правиле и преобразовываться сам в себя. Это необходимо, чтобы избежать зацикливания замены, когда токен постоянно будет преобразовываться из одного в другой, и неоднозначности преобразования, в случае если зацикливание всё же не произойдет.

\section{Алгоритм сортировки токенов по алфавиту}
Токены после применения к ним правил сортируются в лексикографическом порядке. Это значит, что при посимвольном сравнении строк большей (при сортировке по возрастанию) будет считаться та, текущий символ которой имеет меньшее значение кода в рассматриваемой кодировке. Для этого применяется алгоритм быстрой сортировки без шаблонов, описанный в \cite{web_item14}.

\newpage